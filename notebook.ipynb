{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "5a8669a0-f390-49d2-8962-8392a0c94864",
        "_uuid": "70d9f6b17777bc916fcff5cf388fde6411f8cf60"
      },
      "cell_type": "markdown",
      "source": "# Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"
    },
    {
      "metadata": {
        "_cell_guid": "6b4fce61-7dce-4a75-804c-6ab5f2f03cf3",
        "_uuid": "436148cf56758dc986140cb740d4f3cb8c547466"
      },
      "cell_type": "markdown",
      "source": "## 模型介绍\n\n![](https://github.com/applenob/RNN-for-Joint-NLU/raw/master/res/arc.png)\n\n形式化表达整理：\n\n- 输入序列：$x = (x_1,...x_T)$\n- 输出序列：$y = (y_1,...y_T)$，长度和$x$相同。\n- Encoder：时刻i，\n- 隐藏状态：$h_i = [fh_i, bh_i]$，前向状态+后向状态。\n- Decoder：时刻i，\n- 状态：$s_i$，$s_i = f(s_{i-1}, y_{i-1}, h_i, c_i)$\n- 其中，context向量：$c_i$，$c_i = \\sum^{T}_{j=1}\\alpha_{i,j}h_j$\n- attention参数：$\\alpha_{i,j} = \\frac{exp(e_{i,j})}{\\sum^T_{k=1}exp(e_{i,k})}$\n- $e_{i,k} = g(s_{i-1}, h_k)$\n- $g$是一个小型神经网络。"
    },
    {
      "metadata": {
        "_cell_guid": "aa57f1b7-9c87-4edb-af2c-4aaffb08684d",
        "_uuid": "fab47915b39b41dc00d9edc6816f8b9a715309d9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport random\nimport numpy as np\nimport json\nimport numpy.ma as ma\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\n# from data import *\n# from my_metrics import *",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "63667d2c-60e1-4de3-af38-17d396f86e7d",
        "_uuid": "f55d11261a970a8b926923d66ad7f3f143f85207"
      },
      "cell_type": "markdown",
      "source": "* http://www.isca-speech.org/archive/Interspeech_2016/pdfs/1352.PDF\n* https://arxiv.org/pdf/1409.0473.pdf"
    },
    {
      "metadata": {
        "_cell_guid": "c252a3c8-e855-4140-95ce-937228234848",
        "_uuid": "cdab0bd08ec74c7f23750916ce0d6ea6af30f552"
      },
      "cell_type": "markdown",
      "source": "## 数据预处理"
    },
    {
      "metadata": {
        "_cell_guid": "40daf557-5fb5-412c-a8e2-3faa9f53c00c",
        "_uuid": "60f6174e25f8bf914cdf934fdd9b28dd0790ee42",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "flatten = lambda l: [item for sublist in l for item in sublist]  # 二维展成一维\nindex_seq2slot = lambda s, index2slot: [index2slot[i] for i in s]\nindex_seq2word = lambda s, index2word: [index2word[i] for i in s]\ntrain_data = open(\"../input/iob-tagged-frames-dataset2/train2_w_i.iob\", \"r\").readlines()\ntest_data = open(\"../input/iob-tagged-frames-dataset2/train2_w_i.iob\", \"r\").readlines()\ndef data_pipeline(data, length=50):\n    data = [t[:-1] for t in data]  # 去掉'\\n'\n    # 数据的一行像这样：'BOS i want to fly from baltimore to dallas round trip EOS\n    # \\tO O O O O O B-fromloc.city_name O B-toloc.city_name B-round_trip I-round_trip atis_flight'\n    # 分割成这样[原始句子的词，标注的序列，intent]\n    data = [[t.split(\"\\t\")[0].split(\" \"), t.split(\"\\t\")[1].split(\" \")[:-1], t.split(\"\\t\")[1].split(\" \")[-1]] for t in\n            data]\n    data = [[t[0][1:-1], t[1][1:], t[2]] for t in data]  # 将BOS和EOS去掉，并去掉对应标注序列中相应的标注\n    seq_in, seq_out, intent = list(zip(*data))\n    sin = []\n    sout = []\n    # padding，原始序列和标注序列结尾+<EOS>+n×<PAD>\n    for i in range(len(seq_in)):\n        temp = seq_in[i]\n        if len(temp) < length:\n            temp.append('<EOS>')\n            while len(temp) < length:\n                temp.append('<PAD>')\n        else:\n            temp = temp[:length]\n            temp[-1] = '<EOS>'\n        sin.append(temp)\n\n        temp = seq_out[i]\n        if len(temp) < length:\n            while len(temp) < length:\n                temp.append('<PAD>')\n        else:\n            temp = temp[:length]\n            temp[-1] = '<EOS>'\n        sout.append(temp)\n        data = list(zip(sin, sout, intent))\n    return data\ntrain_data_ed = data_pipeline(train_data)\ntest_data_ed = data_pipeline(test_data)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d8d23c9b-d6c4-47dc-8404-9a6609eebb9e",
        "_uuid": "fc57393462b0ce4a1a33c1147d87aaf2456f581e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(train_data_ed[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8da526ce-8da4-48cf-8305-f78c6398e4d7",
        "_uuid": "06ce4e9d0b206774c7bf70caac48119d1a370554"
      },
      "cell_type": "markdown",
      "source": "每行的训练数据是：[加padding后的输入，长度，加padding的标注，intent]"
    },
    {
      "metadata": {
        "_cell_guid": "bc023a3d-4b06-4198-b5ec-022aa8f40244",
        "_uuid": "d64ced5d376bcacbc38327c4c2862d53ad82fbaf",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_info_from_training_data(data):\n    seq_in, seq_out, intent = list(zip(*data))\n    vocab = set(flatten(seq_in))\n    slot_tag = set(flatten(seq_out))\n    intent_tag = set(intent)\n    with open('iob ontology2.json', 'w') as outfile: #by jose\n        json.dump(seq_in, outfile)\n    with open('iob ontology3.json', 'w') as outfile: #by jose\n        json.dump(seq_out, outfile)\n    with open('iob ontology4.json', 'w') as outfile: #by jose\n        json.dump(intent, outfile)\n    # 生成word2index\n    word2index = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n    for token in vocab:\n        if token not in word2index.keys():\n            word2index[token] = len(word2index)\n\n    # 生成index2word\n    index2word = {v: k for k, v in word2index.items()}\n\n    # 生成tag2index\n    tag2index = {'<PAD>': 0, '<UNK>': 1, \"O\": 2}\n    for tag in slot_tag:\n        if tag not in tag2index.keys():\n            tag2index[tag] = len(tag2index)\n\n    # 生成index2tag\n    index2tag = {v: k for k, v in tag2index.items()}\n\n    # 生成intent2index\n    intent2index = {'<UNK>': 0}\n    for ii in intent_tag:\n        if ii not in intent2index.keys():\n            intent2index[ii] = len(intent2index)\n\n    # 生成index2intent\n    index2intent = {v: k for k, v in intent2index.items()}\n    return word2index, index2word, tag2index, index2tag, intent2index, index2intent\n\nword2index, index2word, slot2index, index2slot, intent2index, index2intent = \\\n        get_info_from_training_data(train_data_ed)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e5775dc2-ce59-4765-9844-23a4c33853ab",
        "_uuid": "439a240039a7e8b0aff47ff6e4759f2552d501dc",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def to_index(train, word2index, slot2index, intent2index):\n    new_train = []\n    for sin, sout, intent in train:\n        sin_ix = list(map(lambda i: word2index[i] if i in word2index else word2index[\"<UNK>\"],\n                          sin))\n        true_length = sin.index(\"<EOS>\")\n        sout_ix = list(map(lambda i: slot2index[i] if i in slot2index else slot2index[\"<UNK>\"],\n                           sout))\n        intent_ix = intent2index[intent] if intent in intent2index else intent2index[\"<UNK>\"]\n        new_train.append([sin_ix, true_length, sout_ix, intent_ix])\n    return new_train\nindex_train = to_index(train_data_ed, word2index, slot2index, intent2index)\nindex_test = to_index(test_data_ed, word2index, slot2index, intent2index)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cd5cd1b5-039d-487c-9247-c6249c3dcd40",
        "_uuid": "f938289a50ec6e68fd901f8a878498b54dc41cc0",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(index_train[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "985d4e5f-e505-45ee-a28e-0aeb7768401d",
        "_uuid": "8bdce790ab2cf174ec5fff660297c206e211934b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "input_steps = 50\nembedding_size = 64\nhidden_size = 100\nn_layers = 2\nbatch_size = 16\nvocab_size = 10000\nslot_size = 122\nintent_size = 22\nepoch_num = 5",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d4e20bb1-1cc9-468d-abfa-9ee8851b9306",
        "_uuid": "76e4de0e35cb8d09f810b36127eec2603411baa3"
      },
      "cell_type": "markdown",
      "source": "## Modeling\n\n模型实现。\n\n### Tensorflow的动态rnn\n\n`tf.nn.rnn creates an unrolled graph for a fixed RNN length. That means, if you call tf.nn.rnn with inputs having 200 time steps you are creating a static graph with 200 RNN steps. First, graph creation is slow. Second, you’re unable to pass in longer sequences (> 200) than you’ve originally specified.tf.nn.dynamic_rnn solves this. It uses a tf.While loop to dynamically construct the graph when it is executed. That means graph creation is faster and you can feed batches of variable size.`\n\n摘自[Whats the difference between tensorflow dynamic_rnn and rnn?](https://stackoverflow.com/questions/39734146/whats-the-difference-between-tensorflow-dynamic-rnn-and-rnn)。也就是说，静态的rnn必须提前将图展开，在执行的时候，图是固定的，并且最大长度有限制。而动态rnn可以在执行的时候，将图循环地的复用。\n"
    },
    {
      "metadata": {
        "_cell_guid": "94fae7b8-7083-4849-8e87-151997134d8d",
        "_uuid": "0c12ee63c9ef63714a5c92412fe1702cfef30c59",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "encoder_inputs = tf.placeholder(tf.int32, [input_steps, batch_size],\n                                             name='encoder_inputs')\n# 每句输入的实际长度，除了padding\nencoder_inputs_actual_length = tf.placeholder(tf.int32, [batch_size],\n                                                   name='encoder_inputs_actual_length')\ndecoder_targets = tf.placeholder(tf.int32, [batch_size, input_steps],\n                                      name='decoder_targets')\nintent_targets = tf.placeholder(tf.int32, [batch_size],\n                                     name='intent_targets')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1cc91792-9bca-4f75-91aa-31aa38e36830",
        "_uuid": "b6f54d874d4324b908ff89accb5018c1d5782531"
      },
      "cell_type": "markdown",
      "source": "### embedding"
    },
    {
      "metadata": {
        "_cell_guid": "314ca96b-d22f-4c65-a886-c869b5259d66",
        "_uuid": "a46d5ff59568f6e45d9cf2547d6c0563f7d246d9",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size],\n                                                        -0.1, 0.1), dtype=tf.float32, name=\"embedding\")\n\nencoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fe0b26be-c9bd-43e4-bca2-ae3403db34be",
        "_uuid": "5c3cf3d32707664b4d8d687b9f71b3e1d948334d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "encoder_inputs_embedded",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "08ab9e4d-e3d3-48b6-97cd-5ca503470fed",
        "_uuid": "87b56bdc8a608c37b02660c85273adbcefc6f1f6"
      },
      "cell_type": "markdown",
      "source": "## Encoder"
    },
    {
      "metadata": {
        "_cell_guid": "717cac29-22ae-4c87-8758-88dd1557c70e",
        "_uuid": "d3e9e1c535f8087db5ae312152dabfcf59c78c03",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6aa6263a-88c0-4f68-855f-c4e92d927fbe",
        "_uuid": "51fe2e66c66ff198a1dd1a9d2433e3acbc2d7945",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 使用单个LSTM cell\nencoder_f_cell = LSTMCell(hidden_size)\nencoder_b_cell = LSTMCell(hidden_size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "04bd6504-f854-4ebd-b876-7503dd8884c8",
        "_uuid": "144535af57bfb33b817ca2a0e104881bae925888",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 下面四个变量的尺寸：T*B*D，T*B*D，B*D，B*D\n(encoder_fw_outputs, encoder_bw_outputs), (encoder_fw_final_state, encoder_bw_final_state) = \\\n    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_f_cell,\n                                    cell_bw=encoder_b_cell,\n                                    inputs=encoder_inputs_embedded,\n                                    sequence_length=encoder_inputs_actual_length,\n                                    dtype=tf.float32, time_major=True)\nencoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n\nencoder_final_state_c = tf.concat(\n    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n\nencoder_final_state_h = tf.concat(\n    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n\nencoder_final_state = LSTMStateTuple(\n    c=encoder_final_state_c,\n    h=encoder_final_state_h\n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8a9bf3af-bb77-4727-84b8-ebf965460e35",
        "_uuid": "700e29cb86693816ee0955cc8036b8a2c3f44c99",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(\"encoder_outputs: \", encoder_outputs)\nprint(\"encoder_outputs[0]: \", encoder_outputs[0])\nprint(\"encoder_final_state_c: \", encoder_final_state_c)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "125745f1-e230-441f-a95a-154178cbad8c",
        "_uuid": "318de2c6082a0715d078c49829b788ccaf0fdb5f"
      },
      "cell_type": "markdown",
      "source": "## Decoder"
    },
    {
      "metadata": {
        "_cell_guid": "f1076f45-f2a3-4710-baeb-442a68774cc4",
        "_uuid": "f1d3320afd51dacce2060388a2c2439003d012f8",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "decoder_lengths = encoder_inputs_actual_length",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "35cc4152-1887-4288-b33a-305bb04b3204",
        "_uuid": "1ea4117aed16e7620440f31f8143d1a7bfd143c6",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "slot_W = tf.Variable(tf.random_uniform([hidden_size * 2, slot_size], -1, 1),\n                             dtype=tf.float32, name=\"slot_W\")\nslot_b = tf.Variable(tf.zeros([slot_size]), dtype=tf.float32, name=\"slot_b\")\nintent_W = tf.Variable(tf.random_uniform([hidden_size * 2, intent_size], -0.1, 0.1),\n                               dtype=tf.float32, name=\"intent_W\")\nintent_b = tf.Variable(tf.zeros([intent_size]), dtype=tf.float32, name=\"intent_b\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3100d1a2-b5bf-4949-b435-d61ee7b81be0",
        "_uuid": "d3c57ea2c1b9300b6fafcca63eb784e583e09bdd",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 求intent\nintent_logits = tf.add(tf.matmul(encoder_final_state_h, intent_W), intent_b)\nintent = tf.argmax(intent_logits, axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9f8f10a3-cfda-4429-b662-33194c43636d",
        "_uuid": "f0c00bcbff2357bdaeb6404e4c6873470e547914",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "sos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='SOS') * 2\nsos_step_embedded = tf.nn.embedding_lookup(embeddings, sos_time_slice)\npad_step_embedded = tf.zeros([batch_size, hidden_size * 2 + embedding_size],\n                             dtype=tf.float32)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ad5485c3-bbf4-4463-829a-ba7b2e1ba410",
        "_uuid": "dad925b856ba1982373d16d4be3766f38e9e64cc"
      },
      "cell_type": "markdown",
      "source": "### 开始Hack\n\n像上面Encoder使用的那样，标准的`tf.nn.dynamic_rnn`需要提前将所有的输入都提前包装到一个tensor里传过去。\n\n当Decoder需要使用上一个时间节点的输出时，这就不可能提前包装好。即标准的动态rnn相当于：$s_i = f(s_{i-1}, x_i)$；但如果这个函数的参数需要扩充，比如我们做的：$s_i = f(s_{i-1}, y_{i-1}, h_i, c_i)$。\n\n于是我们需要Hack：使用`tf.contrib.seq2seq.CustomHelper`，传入三个函数：\n\n- `initial_fn()`：第一个时间点的输入。\n- `sample_fn()`：如何从logit到确定的某个固定的类别id。\n- `next_inputs_fn()`：确定一般的时间点的输入。\n"
    },
    {
      "metadata": {
        "_cell_guid": "78ed7150-23cb-4755-82fd-ec485e236ea1",
        "_uuid": "1510564dcb18d6bee2231bb0721c7b2802183f8a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def initial_fn():\n    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n    initial_input = tf.concat((sos_step_embedded, encoder_outputs[0]), 1)\n    return initial_elements_finished, initial_input",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a4ed7fb7-3507-490a-ba55-065031cd72a6",
        "_uuid": "8a2e688d4465b472faab47e1668c31c6653d0493",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def sample_fn(time, outputs, state):\n    # 选择logit最大的下标作为sample\n    prediction_id = tf.to_int32(tf.argmax(outputs, axis=1))\n    return prediction_id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e10044d9-22db-4f47-8efe-174c530d8485",
        "_uuid": "5336aeec6345ea829ef4249f4937a0a08eb39f58",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def next_inputs_fn(time, outputs, state, sample_ids):\n    # 上一个时间节点上的输出类别，获取embedding再作为下一个时间节点的输入\n    pred_embedding = tf.nn.embedding_lookup(embeddings, sample_ids)\n    # 输入是h_i+o_{i-1}+c_i\n    next_input = tf.concat((pred_embedding, encoder_outputs[time]), 1)\n    elements_finished = (time >= decoder_lengths)  # this operation produces boolean tensor of [batch_size]\n    all_finished = tf.reduce_all(elements_finished)  # -> boolean scalar\n    next_inputs = tf.cond(all_finished, lambda: pad_step_embedded, lambda: next_input)\n    next_state = state\n    return elements_finished, next_inputs, next_state",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "43b30b1a-0b55-4c36-936f-5aa64450222b",
        "_uuid": "ff51ac00a4c53d958fdb7f0c210041f853a1589a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 定义自己的helper\nmy_helper = tf.contrib.seq2seq.CustomHelper(initial_fn, sample_fn, next_inputs_fn)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "655073d2-7117-462b-84b8-3cc82edaaa90",
        "_uuid": "5c5786cb93064279917eca138c00979cadf40806",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def decode(helper, scope, reuse=None):\n    with tf.variable_scope(scope, reuse=reuse):\n        memory = tf.transpose(encoder_outputs, [1, 0, 2])\n        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n            num_units=hidden_size, memory=memory,\n            memory_sequence_length=encoder_inputs_actual_length)\n        cell = tf.contrib.rnn.LSTMCell(num_units=hidden_size * 2)\n        attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n            cell, attention_mechanism, attention_layer_size=hidden_size)\n        out_cell = tf.contrib.rnn.OutputProjectionWrapper(\n            attn_cell, slot_size, reuse=reuse\n        )\n        decoder = tf.contrib.seq2seq.BasicDecoder(\n            cell=out_cell, helper=helper,\n            initial_state=out_cell.zero_state(\n                dtype=tf.float32, batch_size=batch_size))\n        # initial_state=encoder_final_state)\n        final_outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(\n            decoder=decoder, output_time_major=True,\n            impute_finished=True, maximum_iterations=input_steps\n        )\n        return final_outputs",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "762d8b4c-5700-4125-a576-ae62ea7352f2",
        "_uuid": "caf2553b27ce02d87e72c230d3eabf790932f49e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "outputs = decode(my_helper, 'decode')\nprint(\"outputs: \", outputs)\nprint(\"outputs.rnn_output: \", outputs.rnn_output)\nprint(\"outputs.sample_id: \", outputs.sample_id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5ca7b512-7e86-4280-9955-69293d782510",
        "_uuid": "e58d2d8e7a0ea35c03bc80ded9e2911150181b33"
      },
      "cell_type": "markdown",
      "source": "注意这里的输出的第一维依然是T，但已经不是之前定义的最大的50，而是当前batch的长度最大值。"
    },
    {
      "metadata": {
        "_cell_guid": "b82be21f-2c00-4954-a7f3-0bce47069f0e",
        "_uuid": "2934ef753d652a0be85bb43cefac22ffc31fcc89",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "decoder_prediction = outputs.sample_id\ndecoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(outputs.rnn_output))\ndecoder_targets_time_majored = tf.transpose(decoder_targets, [1, 0])\ndecoder_targets_true_length = decoder_targets_time_majored[:decoder_max_steps]\nprint(\"decoder_targets_true_length: \", decoder_targets_true_length)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2d6e16ba-d099-437a-8b34-64caeffe46ca",
        "_uuid": "4209dfd61315d11e8b3d3e0acdb45c5f30643d28",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 定义mask，使padding不计入loss计算\nmask = tf.to_float(tf.not_equal(decoder_targets_true_length, 0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6ae61e31-aad4-4478-95eb-9eaae92d8cb5",
        "_uuid": "dc007ea6a97e71947eda38f70c474baf19ff8769",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 定义slot标注的损失\nloss_slot = tf.contrib.seq2seq.sequence_loss(\n    outputs.rnn_output, decoder_targets_true_length, weights=mask)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "422f792d-90db-46e5-88d5-4fd20be44541",
        "_uuid": "00cab09675d25612723d1900ee6087b8ff62398b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 定义intent分类的损失\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n    labels=tf.one_hot(intent_targets, depth=intent_size, dtype=tf.float32),\n    logits=intent_logits)\nloss_intent = tf.reduce_mean(cross_entropy)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ebed0a00-ae40-438f-a064-817feb380a12",
        "_uuid": "30f61a8e1e04eddf194cf61a8514d324ba3453a5",
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## train"
    },
    {
      "metadata": {
        "_cell_guid": "3000a9a3-5be9-4ee2-b724-5f20ffd32b7d",
        "_uuid": "e96177f4077e1b16426d3ead75d7407f93ffd877",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "loss = loss_slot + loss_intent\noptimizer = tf.train.AdamOptimizer(name=\"a_optimizer\")\ngrads, vars = zip(*optimizer.compute_gradients(loss))\ngradients, _ = tf.clip_by_global_norm(grads, 5)  # clip gradients\ntrain_op = optimizer.apply_gradients(zip(grads, vars))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d1d9620d-b06f-402e-bc14-247de0c11494",
        "_uuid": "4683b399b32753a5b2da263e240a4680a95ec73d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def step(sess, mode, trarin_batch):\n    \"\"\" perform each batch\"\"\"\n    if mode not in ['train', 'test']:\n        print >> sys.stderr, 'mode is not supported'\n        sys.exit(1)\n    unziped = list(zip(*trarin_batch))\n    if mode == 'train':\n        output_feeds = [train_op, loss, decoder_prediction,\n                        intent]\n        feed_dict = {encoder_inputs: np.transpose(unziped[0], [1, 0]),\n                     encoder_inputs_actual_length: unziped[1],\n                     decoder_targets: unziped[2],\n                     intent_targets: unziped[3]}\n    if mode in ['test']:\n        output_feeds = [decoder_prediction, intent]\n        feed_dict = {encoder_inputs: np.transpose(unziped[0], [1, 0]),\n                     encoder_inputs_actual_length: unziped[1]}\n#     print(\"feed dict,output feed\",feed_dict,output_feeds)\n    results = sess.run(output_feeds, feed_dict=feed_dict)\n#     print(\"results\",results)\n    return results",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "92253f80-62f1-4b14-9919-d6cef55c3fbe",
        "_uuid": "2cb5aaeee433b7de177a06da8bbf5217e1f448d6",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "sess = tf.Session()\nsess.run(tf.global_variables_initializer())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3b3d46e1-d4b7-4b07-ab04-17365a584aec",
        "_uuid": "757fa30904948b13eac81c16b5bf2a9b4b0fcffd",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def getBatch(batch_size, train_data):\n    random.shuffle(train_data)\n    sindex = 0\n    eindex = batch_size\n    while eindex < len(train_data):\n        batch = train_data[sindex:eindex]\n        temp = eindex\n        eindex = eindex + batch_size\n        sindex = temp\n        yield batch\ndef accuracy_score(true_data, pred_data, true_length=None):\n    true_data = np.array(true_data)\n    pred_data = np.array(pred_data)\n    assert true_data.shape == pred_data.shape\n    if true_length is not None:\n        val_num = np.sum(true_length)\n        assert val_num != 0\n        res = 0\n        for i in range(true_data.shape[0]):\n            res += np.sum(true_data[i, :true_length[i]] == pred_data[i, :true_length[i]])\n    else:\n        val_num = np.prod(true_data.shape)\n        assert val_num != 0\n        res = np.sum(true_data == pred_data)\n    res /= float(val_num)\n    return res\ndef get_data_from_sequence_batch(true_batch, pred_batch, padding_token):\n    \"\"\"从序列的batch中提取数据：\n    [[3,1,2,0,0,0],[5,2,1,4,0,0]] -> [3,1,2,5,2,1,4]\"\"\"\n    true_ma = ma.masked_equal(true_batch, padding_token)\n    pred_ma = ma.masked_array(pred_batch, true_ma.mask)\n    true_ma = true_ma.flatten()\n    pred_ma = pred_ma.flatten()\n    true_ma = true_ma[~true_ma.mask]\n    pred_ma = pred_ma[~pred_ma.mask]\n    return true_ma, pred_ma\n\ndef f1_for_sequence_batch(true_batch, pred_batch, average=\"micro\", padding_token=0):\n    true, pred = get_data_from_sequence_batch(true_batch, pred_batch, padding_token)\n    labels = list(set(true))\n    return f1_score(true, pred, labels=labels, average=average)\n\nfor epoch in range(epoch_num):\n    mean_loss = 0.0\n    train_loss = 0.0\n    for i, batch in enumerate(getBatch(batch_size, index_train)):\n        # 执行一个batch的训练\n        _, loss_v, decoder_prediction_v, intent_v = step(sess, \"train\", batch)\n        mean_loss += loss_v\n        train_loss += loss_v\n        if i % 30 == 0:\n            if i > 0:\n                mean_loss = mean_loss / 30.0\n            print('Average train loss at epoch %d, step %d: %f' % (epoch, i, mean_loss))\n            mean_loss = 0\n    train_loss /= (i + 1)\n    print(\"[Epoch {}] Average train loss: {}\".format(epoch, train_loss))\n\n    # 每训一个epoch，测试一次\n    pred_slots = []\n    for j, batch in enumerate(getBatch(batch_size, index_test)):\n        decoder_prediction_v, intent_v = step(sess, \"test\", batch)\n        decoder_prediction_v = np.transpose(decoder_prediction_v, [1, 0])\n        if j == 0:\n            index = random.choice(range(len(batch)))\n            print(\"Input Sentence        : \", index_seq2word(batch[index][0], index2word))\n            print(\"Slot Truth            : \", index_seq2slot(batch[index][2], index2slot))\n            print(\"Slot Prediction       : \", index_seq2slot(decoder_prediction_v[index], index2slot))\n            print(\"Intent Truth          : \", index2intent[batch[index][3]])\n            print(\"Intent Prediction     : \", index2intent[intent_v[index]])\n        slot_pred_length = list(np.shape(decoder_prediction_v))[1]\n        pred_padded = np.lib.pad(decoder_prediction_v, ((0, 0), (0, input_steps-slot_pred_length)),\n                                 mode=\"constant\", constant_values=0)\n        pred_slots.append(pred_padded)\n        true_slot = np.array((list(zip(*batch))[2]))\n        true_length = np.array((list(zip(*batch))[1]))\n        true_slot = true_slot[:, :slot_pred_length]\n        slot_acc = accuracy_score(true_slot, decoder_prediction_v, true_length)\n        intent_acc = accuracy_score(list(zip(*batch))[3], intent_v)\n        print(\"slot accuracy: {}, intent accuracy: {}\".format(slot_acc, intent_acc))\n    pred_slots_a = np.vstack(pred_slots)\n    true_slots_a = np.array(list(zip(*index_test))[2])[:pred_slots_a.shape[0]]\n    print(\"F1 score for epoch {}: {}\".format(epoch, f1_for_sequence_batch(true_slots_a, pred_slots_a)))\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bc878ab3-1731-42cf-aceb-e4546f96d14c",
        "_uuid": "1b69bcfaf9506b45bfeab864f3087784f1c02edc",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "version": "3.6.4",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "pygments_lexer": "ipython3",
      "name": "python",
      "mimetype": "text/x-python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}